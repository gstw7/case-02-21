{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surrounded-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_RAW_PATH = '../data/raw/'\n",
    "DATA_INTER_PATH = '../data/interim/'\n",
    "FIGURES = '../figures/'\n",
    "DATA_RAW_NAME = 'teste_smarkio_lbs.xls'\n",
    "DATA_INTER_NAME = 'df_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "developed-chamber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_class</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>status</th>\n",
       "      <th>True_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.379377</td>\n",
       "      <td>approved</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.379377</td>\n",
       "      <td>approved</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.420930</td>\n",
       "      <td>approved</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.607437</td>\n",
       "      <td>approved</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.690894</td>\n",
       "      <td>approved</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.759493</td>\n",
       "      <td>approved</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pred_class  probabilidade    status  True_class\n",
       "0           2       0.079892  approved         0.0\n",
       "1           2       0.379377  approved        74.0\n",
       "2           2       0.379377  approved        74.0\n",
       "3           2       0.420930  approved        74.0\n",
       "4           2       0.607437  approved         2.0\n",
       "5           2       0.690894  approved         2.0\n",
       "6           2       0.759493  approved         2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_INTER_PATH+DATA_INTER_NAME)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-pipeline",
   "metadata": {},
   "source": [
    "### Questão 2: \n",
    "#### Calcule o desempenho do modelo de classificação utilizando pelo menos três métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "essential-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adaptive-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['status'] == 'approved']\n",
    "\n",
    "y_true = df['True_class'].tolist()\n",
    "y_pred = df['Pred_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "resident-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall de: 69.83 %\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_true,\n",
    "                     y_pred,\n",
    "                     average='weighted')\n",
    "\n",
    "print('Recall de:',round(recall*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-anniversary",
   "metadata": {},
   "source": [
    "Recall: Mostra proporção de positivos reais está corretamente classificada. Leva em consideração a proporção de falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adapted-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision de: 69.88 %\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true,\n",
    "                        y_pred,\n",
    "                        average='weighted')\n",
    "\n",
    "print('Precision de:',round(precision*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-supply",
   "metadata": {},
   "source": [
    "Precision: Mostra a proporção de positivos que foi previsto que é verdadeiramente positivo. Leva em consideração a proporção de falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reliable-coordinate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score de: 68.31 %\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true,\n",
    "                y_pred,\n",
    "                     average='weighted')\n",
    "\n",
    "print('F1-Score de:',round(f1*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-affiliate",
   "metadata": {},
   "source": [
    "F1-Score: Mostra a média harmônica entre ***Precision*** e ***Recall***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-sterling",
   "metadata": {},
   "source": [
    "### Conclusão:\n",
    "\n",
    "#### Como mostra as métricas acima temos um equilíbrio entre os falsos positivos e falsos negativos que o modelo de classificação previu. O f1-score mostra esse equílibrio na base."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
